Tenho que configurar:

Está no spark-default.conf :
    - spark.driver.memory   (Só modo Cluster) #não tem um limite definido
    - spark.executor.memory (used in YARN deploy mode) #tem de ser menor que a memória total do container yarn
    - spark.yarn.am.memory (Só modo client)

Está no yarn-site.xml :
    - yarn.nodemananger.resource.memory-mb (Memória do container-yarn criado, nos datanodes )
    - yarn.scheduler.maximum-allocation-mb
    - yarn.scheduler.minimum-allocation-mb

Está no mapred-site.xml  :
    - mapreduce.map.memory.mb
    - mapreduce.reduce.memory.mb
    - yarn.app.mapreduce.am.resource.mb


###########################################
KERNEl

/usr/share/jupyter/kernels/

PYTHONSTARTUP 

Pra não ter que criar sessão toda hora utilizar isso